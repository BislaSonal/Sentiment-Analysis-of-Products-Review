{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HmT7x0Mnv-xy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "11d3dce7-5022-4038-c8e6-64d987594fef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bert.ipynb\\n\\nAutomatically generated by Colaboratory.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1hscLaaPEsIoh9nCUfEG9cKXN2ftqpoRv\\n\\n# Sentiment Analysis using BERT\\n\\nBERT (Bidirectionnal Encoder Representations for Transformers) is a “new method of pre-training language representations” developed by Google and released in late 2018.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"bert.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1hscLaaPEsIoh9nCUfEG9cKXN2ftqpoRv\n",
        "\n",
        "# Sentiment Analysis using BERT\n",
        "\n",
        "BERT (Bidirectionnal Encoder Representations for Transformers) is a “new method of pre-training language representations” developed by Google and released in late 2018.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Import Libraries and Set the intial variables\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "# Torch ML libraries\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Misc.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Set intial variables and constants\n",
        "# %config InlineBackend.figure_format='retina'\n",
        "\n",
        "# Graph Designs\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n"
      ],
      "metadata": {
        "id": "NVNVVEKTwD0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845b75a1-e14b-4f6e-b1ff-c671f07f849a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibilty\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# Set GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\"\"\"### Load the data\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/flipkart_processed_output.csv',error_bad_lines=False)\n",
        "df.shape\n",
        "\n",
        "# Let's have a look at the data\n",
        "df.head()\n",
        "\n",
        "\"\"\"We can see that the most relevant column for us is content and replyContent and the score as well.\"\"\"\n",
        "\n",
        "# Let's check for missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "\"\"\"There are missing values in some of the columns but Content and score don't have a missing value. We can also look at the class balance.\n",
        "\n",
        "We will be alloting three classes:-\n",
        "1. Positive (Score: 4-5)\n",
        "2. Neutral (Score: 3)\n",
        "3. Negative (Score: 1-2)\n",
        "\"\"\"\n",
        "\n",
        "# Let's have a look at the class balance.\n",
        "# sns.countplot(df.Rate)\n",
        "# plt.xlabel('review score');\n",
        "\n",
        "\"\"\"We can see that we have more positive classes than negative and low number of neutral class. I have kept neutral less to focus more on positive and negative classes. Let's allot classes based on scores now.\n",
        "\n",
        "* 0 - negative\n",
        "* 1 - neutral\n",
        "* 2 - positive\n",
        "\"\"\"\n",
        "\n",
        "# Map 'Output' column to sentiment classes\n",
        "def map_output_to_sentiment(output):\n",
        "    # print(output)\n",
        "    if output == 'Positive':\n",
        "        return 2\n",
        "    elif output == 'Negative':\n",
        "        return 0\n",
        "    else:\n",
        "        return 1  # Neutral\n",
        "\n",
        "df['sentiment'] = df['Output'].apply(map_output_to_sentiment)\n",
        "# Calculate the counts of each sentiment class\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "# Print the counts\n",
        "print(\"Total Positive Sentiments:\", sentiment_counts[2])\n",
        "print(\"Total Negative Sentiments:\", sentiment_counts[0])\n",
        "print(\"Total Neutral Sentiments:\", sentiment_counts[1])\n",
        "\n",
        "# Plot the distribution\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "class_names = ['positive','negative', 'neutral']\n",
        "# Calculate the sentiment counts\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "# Plot the distribution\n",
        "ax = sns.countplot(x='sentiment', data=df, order=sentiment_counts.index)\n",
        "plt.xlabel('review sentiment')\n",
        "\n",
        "# Set tick labels\n",
        "ax.set_xticklabels(class_names)\n",
        "\n",
        "\"\"\"## Data Preprocessing\n",
        "\n",
        "Machine Learning models don’t work with raw text. You need to convert text to numerical representation. BERT requires even more attention when it comes to this representation.\n",
        "\n",
        "Here are the requirements:\n",
        "\n",
        "* Add special tokens to separate sentences and do classification\n",
        "* Pass sequences of constant length (introduce padding)\n",
        "* Create array of 0s (pad token) and 1s (real token) called attention mask\n",
        "\n",
        "BERT offers a few model architectures and I will be using one of them combined with manual preprocessing. I am using the cased version which considers GREAT and great to be to different entities and BAD might be given more focus than bad.\n",
        "\n",
        "The tokenizer will break the sentence into words and give numerical values to each word.\n",
        "\"\"\"\n",
        "\n",
        "# Set the model name\n",
        "MODEL_NAME = 'bert-base-cased'\n",
        "\n",
        "# Build a BERT based tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Some of the common BERT tokens\n",
        "print(tokenizer.sep_token, tokenizer.sep_token_id) # marker for ending of a sentence\n",
        "print(tokenizer.cls_token, tokenizer.cls_token_id) # start of each sentence, so BERT knows we’re doing classification\n",
        "print(tokenizer.pad_token, tokenizer.pad_token_id) # special token for padding\n",
        "print(tokenizer.unk_token, tokenizer.unk_token_id) # tokens not found in training set\n",
        "\n",
        "\"\"\"BERT works with fixed-length sequences. We’ll use a simple strategy to choose the max length. Let’s store the token length of each review.\"\"\"\n",
        "\n",
        "# Store length of each review\n",
        "token_lens = []\n",
        "\n",
        "# Combine 'Review' and 'Summary' columns to create 'content'\n",
        "df['content'] = df['Review'] + ' ' + df['Summary']\n",
        "\n",
        "# Filter out rows with NaN values in 'content' column\n",
        "df = df.dropna(subset=['content'])\n",
        "\n",
        "# Iterate through the content slide\n",
        "for txt in df.content:\n",
        "    tokens = tokenizer.encode(txt, max_length=512)\n",
        "    token_lens.append(len(tokens))\n",
        "\n",
        "# plot the distribution of review lengths\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count')\n",
        "\n",
        "\"\"\"Most of the reviews seem to contain less than 120 tokens, but we’ll be on the safe side and choose a maximum length of 160.\"\"\"\n",
        "\n",
        "MAX_LEN = 160\n",
        "\n",
        "\"\"\"### Preparing Torch Dataset\n",
        "\n",
        "To enter data into a PyTorch, we need a more robust data generator class. We will return the review text as well to validate our predictions easily.\n",
        "\"\"\"\n",
        "\n",
        "class GPReviewDataset(Dataset):\n",
        "    # Constructor Function\n",
        "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "        self.reviews = reviews\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    # Length magic method\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    # get item magic method\n",
        "    def __getitem__(self, item):\n",
        "        review = str(self.reviews[item])\n",
        "\n",
        "        target = self.targets[item]\n",
        "\n",
        "        # Encoded format to be returned\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        #print(review)\n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(target, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\"\"\"Create a 80% train data and 10% test and 10% validation data\"\"\"\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "print(df_train.shape, df_val.shape, df_test.shape)\n",
        "\n",
        "\"\"\"Create a dataloader to release data in batches.\"\"\"\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = GPReviewDataset(\n",
        "        reviews=df.content.to_numpy(),\n",
        "        targets=df.sentiment.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "# Create train, test and val data loaders\n",
        "BATCH_SIZE = 16\n",
        "# Combine 'Review' and 'Summary' columns to create 'content'\n",
        "df['content'] = df['Review'] + ' ' + df['Summary']\n",
        "\n",
        "# Create train, test, and validation data loaders\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "# Examples\n",
        "data = next(iter(train_data_loader))\n",
        "print(data.keys())\n",
        "\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)\n",
        "\n",
        "\"\"\"## Sentiment Classification with BERT and Hugging Face\n",
        "\n",
        "We’ll use the basic BertModel and build our sentiment classifier on top of it. Let’s load the model\n",
        "\"\"\"\n",
        "\n",
        "# Load the basic BERT model\n",
        "bert_model = BertModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Build the Sentiment Classifier class\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    # Constructor class\n",
        "    def __init__(self, n_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME,return_dict=False)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    # Forward propagaion class\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        _, pooled_output = self.bert(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask\n",
        "        )\n",
        "        #  Add a dropout layer\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n",
        "\n",
        "\"\"\"We use a dropout layer for some regularization and a fully-connected layer for our output. We are returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work. Create an instance and move it to the GPU\"\"\"\n",
        "\n",
        "# Instantiate the model and move to classifier\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "\"\"\"#### Model Characterstics\"\"\"\n",
        "\n",
        "# Number of hidden units\n",
        "print(bert_model.config.hidden_size)\n",
        "\n",
        "\"\"\"### Training Phase\n",
        "\n",
        "we’ll use the AdamW optimizer provided by Hugging Face. It corrects weight decay. We’ll also use a linear scheduler with no warmup\n",
        "\"\"\"\n",
        "\n",
        "# Number of iterations\n",
        "EPOCHS = 10\n",
        "\n",
        "# Optimizer Adam\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Set the loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Function for a single training iteration\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Backward prop\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Descent\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "\"\"\"Write a function to evaluate model performance\"\"\"\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "\n",
        "            # Get model ouptuts\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "\"\"\"Write the training Loop and store the best training state.\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler,\n",
        "        len(df_train)\n",
        "    )\n",
        "\n",
        "    print(f\"Train loss {train_loss} accuracy {train_acc}\")\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        len(df_val)\n",
        "    )\n",
        "\n",
        "    print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/best_model_state.bin')\n",
        "        best_accuracy = val_acc\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"The above took a lot of time but it's finally working. Now, we can plot the training and validation accuracy.\"\"\"\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "# Graph chars\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);\n",
        "\n",
        "\"\"\"### Model Evaluation\"\"\"\n",
        "\n",
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()\n",
        "\n",
        "\"\"\"Define a helper function to get predictions from our models. This is similar to the evaluation function, except that we’re storing the text of the reviews and the predicted probabilities\"\"\"\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "    model = model.eval()\n",
        "\n",
        "    review_texts = []\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            texts = d[\"review_text\"]\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "\n",
        "            # Get outouts\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            review_texts.extend(texts)\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(outputs)\n",
        "            real_values.extend(targets)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "\n",
        "    return review_texts, predictions, prediction_probs, real_values\n",
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "    model,\n",
        "    test_data_loader\n",
        ")\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ntbwn5GwJ_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0b3d51-919e-4530-eb57-1b049af3662e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total Positive Sentiments: 145136\n",
            "Total Negative Sentiments: 20018\n",
            "Total Neutral Sentiments: 24680\n",
            "[SEP] 102\n",
            "[CLS] 101\n",
            "[PAD] 0\n",
            "[UNK] 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(135167, 8) (16896, 8) (16896, 8)\n",
            "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n",
            "768\n",
            "Epoch 1/10\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05w6Mu16kRLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}